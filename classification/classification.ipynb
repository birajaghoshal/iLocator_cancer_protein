{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Featrues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = np.zeros((270, 500, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One image(3k x 3k) owns 90 patches(100x100)\n",
    "two_imgs_list = []\n",
    "six_imgs_list = []\n",
    "size = label['Label'].values.size\n",
    "for i in range(size):\n",
    "    fname = label['ENSGID'].values[i].encode('ascii','ignore').strip(string.punctuation)+'.txt'\n",
    "    tmp = np.loadtxt('patch_features/'+fname).astype(np.float)\n",
    "    for j in range(180):\n",
    "        F[j][i] = tmp[j]\n",
    "    if tmp.shape[0] < 270 :\n",
    "        two_imgs_list.append(i)\n",
    "    else:\n",
    "        for j in range(180, 270):\n",
    "            F[j][i] = tmp[j]\n",
    "    if tmp.shape[0] == 540:\n",
    "        six_imgs_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in six_imgs_list:\n",
    "    if i%2 == 1:\n",
    "        fname = label['ENSGID'].values[i].encode('ascii','ignore').strip(string.punctuation)+'.txt'\n",
    "        tmp = np.loadtxt('patch_features/'+fname).astype(np.float)\n",
    "        for j in range(270, 540):\n",
    "            F[j-270][i] = tmp[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save np.array\n",
    "np.save('./npy/F', F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1 = np.zeros((1,19))\n",
    "F2 = np.zeros((1,19))\n",
    "F3 = np.zeros((1,19))\n",
    "two_imgs_list = []\n",
    "six_imgs_list = []\n",
    "size = label['Label'].values.size\n",
    "for i in range(size):\n",
    "    fname = label['ENSGID'].values[i].encode('ascii','ignore').strip(string.punctuation)+'.txt'\n",
    "    tmp = np.loadtxt('patch_features/'+fname).astype(np.float)\n",
    "    F1 = np.concatenate((F1, tmp[0].reshape(1,-1)), axis=0)\n",
    "    F2 = np.concatenate((F2, tmp[1].reshape(1,-1)), axis=0)\n",
    "    if tmp.shape[0] == 2:\n",
    "        F3 = np.concatenate((F3, np.zeros((1,19))), axis=0)\n",
    "        two_imgs_list.append(i)\n",
    "    else:\n",
    "        F3 = np.concatenate((F3, tmp[2].reshape(1,-1)), axis=0)\n",
    "    if tmp.shape[0] == 6:\n",
    "        six_imgs_list.append(i)\n",
    "F1 = F1[1:, :]\n",
    "F2 = F2[1:, :]\n",
    "F3 = F3[1:, :]\n",
    "\n",
    "# save np.array\n",
    "np.save('F1', F1)\n",
    "np.save('F2', F2)\n",
    "np.save('F3', F3)\n",
    "np.save('label', final_enc_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save np.array\n",
    "np.save('./npy/F1', F1)\n",
    "np.save('./npy/F2', F2)\n",
    "np.save('./npy/F3', F3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matlab Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature = 1097\n",
    "MF1, MF2, MF3 = np.zeros((1,num_feature)), np.zeros((1,num_feature)), np.zeros((1,num_feature))\n",
    "two_imgs_list = []\n",
    "six_imgs_list = []\n",
    "size = label['Label'].values.size\n",
    "for i in range(size):\n",
    "    fname = label['ENSGID'].values[i].encode('ascii','ignore').strip(string.punctuation)+'.txt'\n",
    "    tmp = np.loadtxt('matlabFeature/'+fname).astype(np.float)\n",
    "    MF1 = np.concatenate((MF1, tmp[0].reshape(1,-1)), axis=0)\n",
    "    MF2 = np.concatenate((MF2, tmp[1].reshape(1,-1)), axis=0)\n",
    "    if tmp.shape[0] == 2:\n",
    "        MF3 = np.concatenate((MF3, np.zeros((1,num_feature))), axis=0)\n",
    "        two_imgs_list.append(i)\n",
    "    else:\n",
    "        MF3 = np.concatenate((MF3, tmp[2].reshape(1,-1)), axis=0)\n",
    "    if tmp.shape[0] == 6:\n",
    "        six_imgs_list.append(i)\n",
    "MF1 = MF1[1:, :]\n",
    "MF2 = MF2[1:, :]\n",
    "MF3 = MF3[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in six_imgs_list:\n",
    "    if i%2 == 1:\n",
    "        fname = label['ENSGID'].values[i].encode('ascii','ignore').strip(string.punctuation)+'.txt'\n",
    "        tmp = np.loadtxt('matlabFeature/'+fname).astype(np.float)\n",
    "        MF1[i] = tmp[3]\n",
    "        MF2[i] = tmp[4]\n",
    "        MF3[i] = tmp[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save np.array\n",
    "np.save('./npy/MF1', MF1)\n",
    "np.save('./npy/MF2', MF2)\n",
    "np.save('./npy/MF3', MF3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load *.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matlab feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MF1 = preprocessing.scale(np.load('./npy/MF1.npy'))\n",
    "MF2 = preprocessing.scale(np.load('./npy/MF2.npy'))\n",
    "MF3 = preprocessing.scale(np.load('./npy/MF3.npy'))\n",
    "label = np.load('./npy/label.npy')[:,1:]\n",
    "MF = np.concatenate((MF1, MF2, MF3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1097)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimension reduction - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(random_state=0)\n",
    "pca.fit(MF)\n",
    "num_pc = 100\n",
    "MF1_pca = pca.transform(MF1)[:, :num_pc]\n",
    "MF2_pca = pca.transform(MF2)[:, :num_pc]\n",
    "MF3_pca = pca.transform(MF3)[:, :num_pc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF1_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search CV\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(MF1_pca, label[:,0], \n",
    "#                                                     test_size=.2, random_state=4)\n",
    "\n",
    "# tuned_parameters = [{'C':[0.01, 0.1, 1, 10]}]\n",
    "# scores = ['f1_micro', 'f1_macro']\n",
    "# # scores = ['recall', 'precision']\n",
    "\n",
    "# for score in scores:\n",
    "#     print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "#     clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
    "#     clf.fit(X_train, Y_train)\n",
    "\n",
    "#     print(\"Best parameters set found on development set:\")\n",
    "#     print(clf.best_params_)\n",
    "#     print(\"Grid scores on development set:\")\n",
    "#     means = clf.cv_results_['mean_test_score']\n",
    "#     stds = clf.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#               % (mean, std * 2, params))\n",
    "\n",
    "#     print(\"Detailed classification report:\")\n",
    "#     print(\"The model is trained on the full development set.\")\n",
    "#     print(\"The scores are computed on the full evaluation set.\")\n",
    "#     y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "#     print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 \t micro \t macro\n",
      "train\t 0.614 \t 0.712\n",
      "test\t 0.373 \t 0.307\n"
     ]
    }
   ],
   "source": [
    "# train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(MF1_pca, label, test_size=.2, random_state=4)\n",
    "\n",
    "acc_train, acc_test = [], []\n",
    "rec_train, rec_test = [], []\n",
    "pre_train, pre_test = [], []\n",
    "pred_train_, pred_test_ = [], []\n",
    "\n",
    "# classfiers\n",
    "classifiers = {'svm':SVC(kernel='linear', verbose=True, probability=False, \n",
    "                         random_state=0, C=10),\n",
    "              'LR':LogisticRegression(penalty='l1', C=1, random_state=0),\n",
    "              'RF': RandomForestClassifier(n_estimators=10, criterion='gini', n_jobs=-1),\n",
    "              'lda': LinearDiscriminantAnalysis()}\n",
    "\n",
    "# train and test\n",
    "for i in range(6):\n",
    "    clf = classifiers['LR']\n",
    "    clf.fit(X_train, Y_train[:,i])\n",
    "    pred_train_pb = clf.predict_proba(X_train)\n",
    "    pred_test_pb = clf.predict_proba(X_test)\n",
    "#     pred_train = np.argmax(pred_train_pb, axis=1)\n",
    "#     pred_test = np.argmax(pred_test_pb, axis=1)\n",
    "    pred_train = clf.predict(X_train)\n",
    "    pred_test = clf.predict(X_test)\n",
    "    pred_train_.append(pred_train)\n",
    "    pred_test_.append(pred_test)\n",
    "    # accuracy\n",
    "    acc_train.append(accuracy_score(Y_train[:,i], pred_train))\n",
    "    acc_test.append(accuracy_score(Y_test[:,i], pred_test))\n",
    "    # recall\n",
    "    rec_train.append(metrics.recall_score(Y_train[:,i], pred_train))\n",
    "    rec_test.append(metrics.recall_score(Y_test[:,i], pred_test))\n",
    "    # precision\n",
    "    pre_train.append(metrics.precision_score(Y_train[:,i], pred_train))\n",
    "    pre_test.append(metrics.precision_score(Y_test[:,i], pred_test))\n",
    "\n",
    "# evaluation\n",
    "pred_test_ = np.array(pred_test_)\n",
    "pred_train_ = np.array(pred_train_)\n",
    "print('\\nF1 \\t micro \\t macro')\n",
    "print('train\\t %.3f \\t %.3f'%(f1_score(Y_train, np.transpose(pred_train_), average='micro'), \n",
    "                           f1_score(Y_train, np.transpose(pred_train_), average='macro')))\n",
    "print('test\\t %.3f \\t %.3f'%(f1_score(Y_test, np.transpose(pred_test_), average='micro'),\n",
    "                           f1_score(Y_test, np.transpose(pred_test_), average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # evaluation\n",
    "\n",
    "# print('accuracy_train:')\n",
    "# print(acc_train)\n",
    "\n",
    "# print('accuracy_test:')\n",
    "# print(acc_test)\n",
    "\n",
    "# print('\\n recall_train:')\n",
    "# print(rec_train)\n",
    "\n",
    "# print('recall_test:')\n",
    "# print(rec_test)\n",
    "\n",
    "# print('\\n precision_train:')\n",
    "# print(pre_train)\n",
    "\n",
    "# print('precision_test:')\n",
    "# print(pre_test)\n",
    "\n",
    "# print('\\n F1_micro')\n",
    "# print('train %.3f'%f1_score(Y_train, np.transpose(pred_train_), average='micro'))\n",
    "# print('test %.3f'%f1_score(Y_test, np.transpose(pred_test_), average='micro'))\n",
    "\n",
    "# print('\\n F1_macro')\n",
    "# print('train %.3f'%f1_score(Y_train, np.transpose(pred_train_), average='macro'))\n",
    "# print('test %.3f'%f1_score(Y_test, np.transpose(pred_test_), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimension reduction - manifold learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(MF1, label, test_size=.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isomap\n",
    "isomap = manifold.Isomap(n_neighbors=300, n_jobs=-1, n_components=100)\n",
    "isomap.fit(MF1)\n",
    "X_train_new = isomap.transform(X_train)\n",
    "X_test_new = isomap.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LLE\n",
    "lle = manifold.LocallyLinearEmbedding(n_jobs=-1, n_components=100, n_neighbors=10)\n",
    "lle.fit(MF1)\n",
    "X_train_new = lle.transform(X_train)\n",
    "X_test_new = lle.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "tsne = manifold.TSNE(n_components=3, perplexity=20, learning_rate=200, verbose=1)\n",
    "tsne.fit(MF1)\n",
    "X_train_new = lle.transform(X_train)\n",
    "X_test_new = lle.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train, acc_test = [], []\n",
    "rec_train, rec_test = [], []\n",
    "pre_train, pre_test = [], []\n",
    "pred_train_, pred_test_ = [], []\n",
    "\n",
    "# classfiers\n",
    "classifiers = {'svm':SVC(kernel='linear', verbose=True, probability=False, \n",
    "                         random_state=0, C=10),\n",
    "              'LR':LogisticRegression(penalty='l1', C=1, random_state=0),\n",
    "              'RF': RandomForestClassifier(n_estimators=10, criterion='gini', n_jobs=-1),\n",
    "              'lda': LinearDiscriminantAnalysis()}\n",
    "\n",
    "# train and test\n",
    "for i in range(6):\n",
    "    clf = classifiers['LR']\n",
    "    clf.fit(X_train_new, Y_train[:,i])\n",
    "#     pred_train_pb = clf.predict_proba(X_train_new)\n",
    "#     pred_test_pb = clf.predict_proba(X_test_new)\n",
    "#     pred_train = np.argmax(pred_train_pb, axis=1)\n",
    "#     pred_test = np.argmax(pred_test_pb, axis=1)\n",
    "    pred_train = clf.predict(X_train_new)\n",
    "    pred_test = clf.predict(X_test_new)\n",
    "    pred_train_.append(pred_train)\n",
    "    pred_test_.append(pred_test)\n",
    "    # accuracy\n",
    "    acc_train.append(accuracy_score(Y_train[:,i], pred_train))\n",
    "    acc_test.append(accuracy_score(Y_test[:,i], pred_test))\n",
    "    # recall\n",
    "    rec_train.append(metrics.recall_score(Y_train[:,i], pred_train))\n",
    "    rec_test.append(metrics.recall_score(Y_test[:,i], pred_test))\n",
    "    # precision\n",
    "    pre_train.append(metrics.precision_score(Y_train[:,i], pred_train))\n",
    "    pre_test.append(metrics.precision_score(Y_test[:,i], pred_test))\n",
    "\n",
    "# evaluation\n",
    "pred_test_ = np.array(pred_test_)\n",
    "pred_train_ = np.array(pred_train_)\n",
    "print('\\nF1 \\t micro \\t macro')\n",
    "print('train\\t %.3f \\t %.3f'%(f1_score(Y_train, np.transpose(pred_train_), average='micro'), \n",
    "                           f1_score(Y_train, np.transpose(pred_train_), average='macro')))\n",
    "print('test\\t %.3f \\t %.3f'%(f1_score(Y_test, np.transpose(pred_test_), average='micro'),\n",
    "                           f1_score(Y_test, np.transpose(pred_test_), average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection - Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(MF1, label, test_size=.2, random_state=4)\n",
    "\n",
    "acc_train, acc_test = [], []\n",
    "rec_train, rec_test = [], []\n",
    "pre_train, pre_test = [], []\n",
    "pred_train_, pred_test_ = [], []\n",
    "\n",
    "# classfiers\n",
    "classifiers = {'svm':SVC(kernel='linear', verbose=True, probability=False, \n",
    "                         random_state=0, C=10),\n",
    "              'LR':LogisticRegression(penalty='l2', C=0.1, random_state=0),\n",
    "              'RF': RandomForestClassifier(n_estimators=10, criterion='gini', n_jobs=-1)}\n",
    "\n",
    "# train and test\n",
    "for i in range(6):\n",
    "    print('%d...'%(i+1))\n",
    "    sel_k = SelectKBest(mutual_info_classif, k=100).fit(X_train, Y_train[:,i])\n",
    "    X_train_new = sel_k.transform(X_train)\n",
    "    X_test_new = sel_k.transform(X_test)\n",
    "    clf = classifiers['LR']\n",
    "    clf.fit(X_train_new, Y_train[:,i])\n",
    "#     pred_train_pb = svm.predict_proba(X_train)\n",
    "#     pred_test_pb = svm.predict_proba(X_test)\n",
    "#     pred_train = np.argmax(pred_train_pb, axis=1)\n",
    "#     pred_test = np.argmax(pred_test_pb, axis=1)\n",
    "    pred_train = clf.predict(X_train_new)\n",
    "    pred_test = clf.predict(X_test_new)\n",
    "    pred_train_.append(pred_train)\n",
    "    pred_test_.append(pred_test)\n",
    "    # accuracy\n",
    "    acc_train.append(accuracy_score(Y_train[:,i], pred_train))\n",
    "    acc_test.append(accuracy_score(Y_test[:,i], pred_test))\n",
    "    # recall\n",
    "    rec_train.append(metrics.recall_score(Y_train[:,i], pred_train))\n",
    "    rec_test.append(metrics.recall_score(Y_test[:,i], pred_test))\n",
    "    # precision\n",
    "    pre_train.append(metrics.precision_score(Y_train[:,i], pred_train))\n",
    "    pre_test.append(metrics.precision_score(Y_test[:,i], pred_test))\n",
    "\n",
    "# evaluation\n",
    "pred_test_ = np.array(pred_test_)\n",
    "pred_train_ = np.array(pred_train_)\n",
    "print('\\nF1 \\t micro \\t macro')\n",
    "print('train\\t %.3f \\t %.3f'%(f1_score(Y_train, np.transpose(pred_train_), average='micro'), \n",
    "                           f1_score(Y_train, np.transpose(pred_train_), average='macro')))\n",
    "print('test\\t %.3f \\t %.3f'%(f1_score(Y_test, np.transpose(pred_test_), average='micro'),\n",
    "                           f1_score(Y_test, np.transpose(pred_test_), average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = np.load('./npy/F.npy')\n",
    "label = np.load('./npy/label.npy')[:,1:]\n",
    "for i in range(180):\n",
    "    F[i] = preprocessing.scale(F[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_train, acc_test = [], []\n",
    "# rec_train, rec_test = [], []\n",
    "# pre_train, pre_test = [], []\n",
    "res_train, res_test = [], []\n",
    "svm = SVC(kernel='poly', verbose=True, probability=True, random_state=0, degree=3)\n",
    "for i in range(6):\n",
    "    X_train, Y_train = F[1][train_idx], label[train_idx][:,i]\n",
    "    X_test, Y_test = F[1][test_idx], label[test_idx][:,i]\n",
    "    svm.fit(X_train, Y_train)\n",
    "#     pred_train_pb = svm.predict_proba(X_train)\n",
    "#     pred_test_pb = svm.predict_proba(X_test)\n",
    "#     pred_train = np.argmax(pred_train_pb, axis=1)\n",
    "#     pred_test = np.argmax(pred_test_pb, axis=1)\n",
    "    pred_train_ = svm.predict(X_train)\n",
    "    pred_test_ = svm.predict(X_test)\n",
    "    res_train.append(pred_train_)\n",
    "    res_test.append(pred_test_)\n",
    "#     # accuracy\n",
    "#     acc_train.append(accuracy_score(Y_train, pred_train))\n",
    "#     acc_test.append(accuracy_score(Y_test, pred_test))\n",
    "#     # recall\n",
    "#     rec_train.append(metrics.recall_score(Y_train, pred_train))\n",
    "#     rec_test.append(metrics.recall_score(Y_test, pred_test))\n",
    "#     # precision\n",
    "#     pre_train.append(metrics.precision_score(Y_train, pred_train))\n",
    "#     pre_test.append(metrics.precision_score(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "np.random.seed(36)\n",
    "permute = np.random.permutation(np.arange(500))\n",
    "train_idx = permute[:400]\n",
    "test_idx = permute[400:]\n",
    "\n",
    "X_train = np.zeros((1,19))\n",
    "num_patch = 180\n",
    "for patch in range(num_patch):\n",
    "    X_train = np.concatenate((X_train, F[patch][train_idx]), axis=0)\n",
    "X_train = X_train[1:,:]\n",
    "Y_train = []\n",
    "for i in range(6):\n",
    "    tmp = np.repeat(label[train_idx][:, i], num_patch)\n",
    "    Y_train.append(tmp)\n",
    "Y_train = np.array(Y_train)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF = [RandomForestClassifier(verbose=False, n_jobs=-1, random_state=i) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# traing and predicting\n",
    "num_patch = 180\n",
    "num_class = 6\n",
    "res_train, res_test = [], []\n",
    "for i in range(num_class):\n",
    "    print('fitting class %d'%i)\n",
    "    RF[i].fit(X_train, Y_train[i])\n",
    "    res_train_, res_test_ = [], []\n",
    "    for patch in range(num_patch):\n",
    "        if (patch+1)%10 == 0:\n",
    "            print('\\t predicting patch %d'%(patch+1))\n",
    "        X_tra, Y_tra = F[patch][train_idx], label[train_idx][:,i]\n",
    "        X_test, Y_test = F[patch][test_idx], label[test_idx][:,i]\n",
    "        pred_train = RF[i].predict_proba(X_tra)\n",
    "        pred_test = RF[i].predict_proba(X_test)\n",
    "        res_train_.append(pred_train)\n",
    "        res_test_.append(pred_test)\n",
    "    res_train.append(res_train_)\n",
    "    res_test.append(res_test_)\n",
    "res_train = np.array(res_train)\n",
    "res_test = np.array(res_test)\n",
    "print(res_test.shape)\n",
    "print(res_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_percent = []\n",
    "test_percent = []\n",
    "for i in range(6):\n",
    "    train_percent.append(1.*np.sum(label[train_idx][:,i])/400)\n",
    "    test_percent.append(1.*np.sum(label[test_idx][:,i])/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_res_train = np.zeros(train.shape).astype(int)\n",
    "f_res_test = np.zeros(test.shape).astype(int)\n",
    "for i in range(6):\n",
    "    # test\n",
    "    test_true_idx = np.flip(np.argsort(test[i]), axis=0)[:int(round(train_percent[i]*100))]\n",
    "    f_res_test[i][test_true_idx] = 1\n",
    "    # train\n",
    "    train_true_idx = np.flip(np.argsort(train[i]), axis=0)[:int(round(train_percent[i]*100))]\n",
    "    f_res_train[i][train_true_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel='poly', verbose=True, probability=True, random_state=0, degree=3)\n",
    "num_patch = 180\n",
    "res_train_, res_test_ = [], []\n",
    "for patch in range(num_patch):\n",
    "    print(patch)\n",
    "    X_train, X_test = F[patch][train_idx], F[patch][test_idx]\n",
    "    res_train, res_test = [], []\n",
    "    for i in range(6):\n",
    "        Y_train, Y_test = label[train_idx][:, i], label[test_idx][:, i]\n",
    "        svm.fit(X_train, Y_train)\n",
    "        pred_train = svm.predict(X_train)\n",
    "        pred_test = svm.predict(X_test)\n",
    "        res_train.append(pred_train_)\n",
    "        res_test.append(pred_test_)\n",
    "    res_train_.append(res_train)\n",
    "    res_test_.append(res_test)\n",
    "res_test_ = np.array(res_test_)\n",
    "res_train_ = np.array(res_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# br = OneVsRestClassifier(SVC(kernel='poly', probability=False, \n",
    "#                              random_state=0, degree=3, verbose=True),\n",
    "#                          n_jobs=-1)\n",
    "# br.fit(F[1][test_idx], label[test_idx])\n",
    "# # pred_train_pb = br.predict_proba(F[1][train_idx])\n",
    "# # pred_test_pb = br.predict_proba(F[1][test_idx])\n",
    "# pred_train = br.predict(F[1][train_idx])\n",
    "# pred_test = br.predict(F[1][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.random.seed(4)\n",
    "# permute = np.random.permutation(np.arange(500))\n",
    "# train_idx = permute[:400]\n",
    "# test_idx = permute[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_1 = np.zeros((1,19))\n",
    "# X_train_2 = np.zeros((1,19))\n",
    "# X_train_3 = np.zeros((1,19))\n",
    "# for i in train_idx:\n",
    "#     X_train_1 = np.concatenate((X_train_1, PF1[i*90:(i+1)*90]), axis=0)\n",
    "#     X_train_2 = np.concatenate((X_train_2, PF2[i*90:(i+1)*90]), axis=0)\n",
    "#     X_train_3 = np.concatenate((X_train_3, PF3[i*90:(i+1)*90]), axis=0)\n",
    "# X_train_1 = X_train_1[1:]\n",
    "# X_train_2 = X_train_2[1:]\n",
    "# X_train_3 = X_train_3[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_test_1 = np.zeros((1,19))\n",
    "# X_test_2 = np.zeros((1,19))\n",
    "# X_test_3 = np.zeros((1,19))\n",
    "# for i in test_idx:\n",
    "#     X_test_1 = np.concatenate((X_test_1, PF1[i*90:(i+1)*90]), axis=0)\n",
    "#     X_test_2 = np.concatenate((X_test_2, PF2[i*90:(i+1)*90]), axis=0)\n",
    "#     X_test_3 = np.concatenate((X_test_3, PF3[i*90:(i+1)*90]), axis=0)\n",
    "# X_test_1 = X_test_1[1:]\n",
    "# X_test_2 = X_test_2[1:]\n",
    "# X_test_3 = X_test_3[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y_train = np.zeros((1,6)).astype(int)\n",
    "# for i in train_idx:\n",
    "#     Y_train = np.concatenate((Y_train, np.repeat(label[i:i+1], 90, axis=0)), axis=0)\n",
    "# Y_train = Y_train[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y_test = label[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in two_imgs_list:\n",
    "#     if i in train_idx:\n",
    "# #         print(i)\n",
    "#         idx = np.argwhere(train_idx==i)[0,0]\n",
    "# #         print(X_train_3[idx*90:(idx+1)*90])\n",
    "#     if i in test_idx:\n",
    "# #         print(i)\n",
    "#         idx = np.argwhere(test_idx==i)[0,0]\n",
    "# #         print(X_test_3[idx*90:(idx+1)*90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole image feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    print('class %d: %.2f '%(i, 100.*np.sum(Y_train[:,i])/Y_train[:,i].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1 = preprocessing.scale(np.load('./npy/F1.npy'))\n",
    "F2 = preprocessing.scale(np.load('./npy/F2.npy'))\n",
    "F3 = preprocessing.scale(np.load('./npy/F3.npy'))\n",
    "label = np.load('./npy/label.npy')[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(F1, label, test_size=.2, random_state=4)\n",
    "acc_train, acc_test = [], []\n",
    "rec_train, rec_test = [], []\n",
    "pre_train, pre_test = [], []\n",
    "for i in range(6):\n",
    "    svm = SVC(kernel='poly', verbose=True, probability=True, random_state=0)\n",
    "    svm.fit(X_train, Y_train[:,i])\n",
    "    pred_train_pb = svm.predict_proba(X_train)\n",
    "    pred_test_pb = svm.predict_proba(X_test)\n",
    "    pred_train = np.argmax(pred_train_pb, axis=1)\n",
    "    pred_test = np.argmax(pred_test_pb, axis=1)\n",
    "    # accuracy\n",
    "    acc_train.append(accuracy_score(Y_train[:,i], pred_train))\n",
    "    acc_test.append(accuracy_score(Y_test[:,i], pred_test))\n",
    "    # recall\n",
    "    rec_train.append(metrics.recall_score(Y_train[:,i], pred_train))\n",
    "    rec_test.append(metrics.recall_score(Y_test[:,i], pred_test))\n",
    "    # precision\n",
    "    pre_train.append(metrics.precision_score(Y_train[:,i], pred_train))\n",
    "    pre_test.append(metrics.precision_score(Y_test[:,i], pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('accuracy_train:')\n",
    "print(acc_train)\n",
    "\n",
    "print('accuracy_test:')\n",
    "print(acc_test)\n",
    "\n",
    "print('\\nrecall_train:')\n",
    "print(rec_train)\n",
    "\n",
    "print('recall_test:')\n",
    "print(rec_test)\n",
    "\n",
    "print('\\nprecision_train:')\n",
    "print(pre_train)\n",
    "\n",
    "print('precision_test:')\n",
    "print(pre_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(F2, label, test_size=.2, random_state=4)\n",
    "acc_train, acc_test = [], []\n",
    "for i in range(6):\n",
    "    svm = SVC(kernel='poly', verbose=True, probability=True, random_state=0)\n",
    "    svm.fit(X_train, Y_train[:,i])\n",
    "    pred_train = svm.predict(X_train)\n",
    "    pred_test = svm.predict(X_test)\n",
    "    acc_train.append(accuracy_score(pred_train, Y_train[:,i]))\n",
    "    acc_test.append(accuracy_score(pred_test, Y_test[:,i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_test)\n",
    "print(acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(F3, label, test_size=.2, random_state=4)\n",
    "acc_train, acc_test = [], []\n",
    "for i in range(6):\n",
    "    svm = SVC(kernel='poly', verbose=True, probability=True, random_state=0)\n",
    "    svm.fit(X_train, Y_train[:,i])\n",
    "    pred_train = svm.predict(X_train)\n",
    "    pred_test = svm.predict(X_test)\n",
    "    acc_train.append(accuracy_score(pred_train, Y_train[:,i]))\n",
    "    acc_test.append(accuracy_score(pred_test, Y_test[:,i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_test)\n",
    "print(acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train, acc_test = [], []\n",
    "for train_index, test_index in kf.split(F2):\n",
    "    X_train, X_test = F2[train_index], F2[test_index]\n",
    "    Y_train, Y_test = label[train_index], label[test_index]\n",
    "    acc_tr, acc_te = [], []\n",
    "    for i in range(6):\n",
    "        svm = SVC(kernel='rbf', verbose=True, probability=True, random_state=0, degree=5)\n",
    "        svm.fit(X_train, Y_train[:,i])\n",
    "        pred_train = svm.predict(X_train)\n",
    "        pred_test = svm.predict(X_test)\n",
    "        acc_tr.append(accuracy_score(pred_train, Y_train[:,i]))\n",
    "        acc_te.append(accuracy_score(pred_test, Y_test[:,i]))\n",
    "    acc_train.append(acc_tr)\n",
    "    acc_test.append(acc_te)\n",
    "acc_test = np.array(acc_test)\n",
    "acc_train = np.array(acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(acc_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chains = [ClassifierChain(SVC(kernel='poly', probability=True, random_state=0, verbose=True), \n",
    "                          order='random', random_state=i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chain in enumerate(chains):\n",
    "    print('\\nchain %d: '%i)\n",
    "    chain.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_train_chains_pb = np.array([chain.predict_proba(X_train) for chain in chains])\n",
    "pred_train_ensemble_pb = pred_train_chains_pb.mean(axis=0)\n",
    "pred_train_ens = np.argmax(pred_train_ensemble_pb, axis=1)\n",
    "\n",
    "pred_test_chains_pb = np.array([chain.predict_proba(X_test) for chain in chains])\n",
    "pred_test_ensemble_pb = pred_test_chains_pb.mean(axis=0)\n",
    "pred_test_ens = np.argmax(pred_test_ensemble_pb, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_train_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(f1_score(Y_train, pred_train_ens, average='macro'))\n",
    "# print(f1_score(Y_train, pred_train_ens, average='micro'))\n",
    "# print(f1_score(Y_test, pred_test_ens, average='macro'))\n",
    "# print(f1_score(Y_test, pred_test_ens, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "br = OneVsRestClassifier(SVC(kernel='poly', probability=True, random_state=0, degree=4))\n",
    "br.fit(X_train, Y_train)\n",
    "pred_train_pb = br.predict_proba(X_train)\n",
    "pred_test_pb = br.predict_proba(X_test)\n",
    "pred_train = br.predict(X_train)\n",
    "pred_test = br.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f1_score(Y_train, pred_train, average='macro'))\n",
    "print(f1_score(Y_train, pred_train, average='micro'))\n",
    "print(f1_score(Y_test, pred_test, average='macro'))\n",
    "print(f1_score(Y_test, pred_test, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "br.fit(X_train, Y_train)\n",
    "pred_train = br.predict(X_train)\n",
    "pred_test = br.predict(X_test)\n",
    "print(f1_score(Y_train, pred_train, average='macro'))\n",
    "print(f1_score(Y_train, pred_train, average='micro'))\n",
    "print(f1_score(Y_test, pred_test, average='macro'))\n",
    "print(f1_score(Y_test, pred_test, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "br = OneVsRestClassifier(LogisticRegression())\n",
    "br.fit(X_train, Y_train)\n",
    "pred_train = br.predict(X_train)\n",
    "pred_test = br.predict(X_test)\n",
    "print(f1_score(Y_train, pred_train, average='macro'))\n",
    "print(f1_score(Y_train, pred_train, average='micro'))\n",
    "print(f1_score(Y_test, pred_test, average='macro'))\n",
    "print(f1_score(Y_test, pred_test, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
