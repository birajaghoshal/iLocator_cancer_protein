{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "probability prediction is saved in 'test_pb.txt'\n",
    "class prediction is saved in 'test_one_hot.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MF1, MF2, MF3, two_imgs_list, six_imgs_list = read_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load\n",
    "F1 = np.load('./npy/MF1.npy')\n",
    "F2 = np.load('./npy/MF2.npy')\n",
    "F3 = np.load('./npy/MF3.npy')\n",
    "label = np.load('./npy/label.npy')[:,1:]\n",
    "\n",
    "all_feature = preprocessing.scale(np.concatenate((MF1, MF2, MF3, F1, F2,F3), axis=0))\n",
    "\n",
    "# test\n",
    "MF1 = all_feature[0:66]\n",
    "MF2 = all_feature[66:132]\n",
    "MF3 = all_feature[132:198]\n",
    "# train\n",
    "F1 = all_feature[198:698]\n",
    "F2 = all_feature[698:1198]\n",
    "F3 = all_feature[1198:1698]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(random_state=0)\n",
    "pca.fit(all_feature)\n",
    "num_pc = 100\n",
    "\n",
    "# train\n",
    "F1_pca = pca.transform(F1)[:, :num_pc]\n",
    "F2_pca = pca.transform(F2)[:, :num_pc]\n",
    "F3_pca = pca.transform(F3)[:, :num_pc]\n",
    "# test\n",
    "MF1_pca = pca.transform(MF1)[:, :num_pc]\n",
    "MF2_pca = pca.transform(MF2)[:, :num_pc]\n",
    "MF3_pca = pca.transform(MF3)[:, :num_pc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "num_chain = 20\n",
    "pred_train_pb, pred_test_pb = [], []\n",
    "test_pca = [MF1_pca, MF2_pca, MF3_pca]\n",
    "train_pca = [F1_pca, F2_pca, F3_pca]\n",
    "for i in range(3):\n",
    "    X_train, Y_train = train_pca[i], label\n",
    "    X_test = test_pca[i]\n",
    "    \n",
    "    chains = [ClassifierChain(LogisticRegression(C=0.01, penalty='l2'), \n",
    "                          order='random', random_state=i) for i in range(num_chain)]\n",
    "    \n",
    "    for i, chain in enumerate(chains):\n",
    "        chain.fit(X_train, Y_train)\n",
    "\n",
    "    # predict\n",
    "    pred_train_chains_pb = np.array([chain.predict_proba(X_train) for chain in chains])\n",
    "    pred_train_ensemble_pb = pred_train_chains_pb.mean(axis=0)\n",
    "#     pred_train_ens = np.argmax(pred_train_ensemble_pb, axis=1)\n",
    "\n",
    "    pred_test_chains_pb = np.array([chain.predict_proba(X_test) for chain in chains])\n",
    "    pred_test_ensemble_pb = pred_test_chains_pb.mean(axis=0)\n",
    "#     pred_test_ens = np.argmax(pred_test_ensemble_pb, axis=1)\n",
    "\n",
    "    pred_train_pb.append(pred_train_ensemble_pb)\n",
    "    pred_test_pb.append(pred_test_ensemble_pb)\n",
    "\n",
    "pred_train_pb = np.array(pred_train_pb)\n",
    "pred_test_pb = np.array(pred_test_pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submit probability\n",
    "res_train_pb = np.max(pred_train_pb, axis=0)\n",
    "res_test_pb = np.max(pred_test_pb, axis=0)\n",
    "res_test_pb[29] = np.max(np.concatenate((pred_test_pb[0][29].reshape(1,-1), pred_test_pb[1][29].reshape(1,-1)), axis=0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 \t micro \t macro\n",
      "train\t 0.557 \t 0.488\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "pred_train_onehot = (res_train_pb >= threshold).astype(int)\n",
    "pred_test_onehot = (res_test_pb >= threshold).astype(int)\n",
    "print('\\nF1 \\t micro \\t macro')\n",
    "print('train\\t %.3f \\t %.3f'%(f1_score(Y_train, pred_train_onehot, average='micro'), \n",
    "                           f1_score(Y_train, pred_train_onehot, average='macro')))\n",
    "# print('test\\t %.3f \\t %.3f'%(f1_score(Y_test, pred_test_onehot, average='micro'), \n",
    "#                            f1_score(Y_test, pred_test_onehot, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_max_pb = np.max(pred_train_pb, axis=0)\n",
    "test_max_pb = np.max(pred_test_pb, axis=0)\n",
    "train_sort = np.argsort(train_max_pb , axis=1)\n",
    "test_sort = np.argsort(test_max_pb, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sum = np.sum(pred_train_onehot,axis=1)\n",
    "test_sum = np.sum(pred_test_onehot,axis=1)\n",
    "for i in range(500):\n",
    "    if train_sum[i] > 3:\n",
    "        pred_train_onehot[i] = np.zeros(6)\n",
    "        for j in [3,4,5]:\n",
    "            pred_train_onehot[i][train_sort[i][j]] = 1\n",
    "\n",
    "for i in range(66):\n",
    "    if test_sum[i] > 3:\n",
    "        pred_test_onehot[i] = np.zeros(6)\n",
    "        for j in [3,4,5]:\n",
    "            pred_test_onehot[i][test_sort[i][j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 \t micro \t macro\n",
      "train\t 0.567 \t 0.502\n"
     ]
    }
   ],
   "source": [
    "print('\\nF1 \\t micro \\t macro')\n",
    "print('train\\t %.3f \\t %.3f'%(f1_score(Y_train, pred_train_onehot, average='micro'), \n",
    "                           f1_score(Y_train, pred_train_onehot, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save results\n",
    "np.save('test_one_hot', pred_test_onehot)\n",
    "np.save('test_pb', res_test_pb)\n",
    "np.savetxt('test_one_hot', pred_test_onehot, fmt='%i')\n",
    "np.savetxt('test_pb', res_test_pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read feature\n",
    "def read_feature():\n",
    "    num_feature = 1097\n",
    "    MF1, MF2, MF3 = np.zeros((1,num_feature)), np.zeros((1,num_feature)), np.zeros((1,num_feature))\n",
    "    two_imgs_list = []\n",
    "    six_imgs_list = []\n",
    "    size = 66\n",
    "    for i in range(size):\n",
    "        fname = '%d.txt'%(i+1)\n",
    "        tmp = np.loadtxt('testFeature/'+fname).astype(np.float)\n",
    "        MF1 = np.concatenate((MF1, tmp[0].reshape(1,-1)), axis=0)\n",
    "        MF2 = np.concatenate((MF2, tmp[1].reshape(1,-1)), axis=0)\n",
    "        if tmp.shape[0] == 2:\n",
    "            MF3 = np.concatenate((MF3, tmp[1].reshape(1,-1)), axis=0)\n",
    "            two_imgs_list.append(i)\n",
    "        else:\n",
    "            MF3 = np.concatenate((MF3, tmp[2].reshape(1,-1)), axis=0)\n",
    "        if tmp.shape[0] == 6:\n",
    "            six_imgs_list.append(i)\n",
    "    MF1 = MF1[1:, :]\n",
    "    MF2 = MF2[1:, :]\n",
    "    MF3 = MF3[1:, :]\n",
    "\n",
    "    for i in six_imgs_list:\n",
    "        if i%2 == 1:\n",
    "            fname = label['ENSGID'].values[i].encode('ascii','ignore').strip(string.punctuation)+'.txt'\n",
    "            tmp = np.loadtxt('testFeature/'+fname).astype(np.float)\n",
    "            MF1[i] = tmp[3]\n",
    "            MF2[i] = tmp[4]\n",
    "            MF3[i] = tmp[5]\n",
    "\n",
    "#     MF1 = preprocessing.scale(MF1)\n",
    "#     MF2 = preprocessing.scale(MF2)\n",
    "#     MF3 = preprocessing.scale(MF3)\n",
    "\n",
    "    return MF1, MF2, MF3, two_imgs_list, six_imgs_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
